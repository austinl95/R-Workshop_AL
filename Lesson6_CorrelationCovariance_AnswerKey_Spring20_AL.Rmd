---
title: "Lesson6_CorrelationCovariance_AnswerKey_Spring20_AL"
author: "Austin Luor"
date: "5/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Lesson 6: Correlation and Covariance

In this lesson, we will be going through our first statistics lesson of the series! We will learn how to use R syntax to create and customize corrlation matrices. In addition, we will also learn the actual computation that goes into correlation. Finally, we will go over some methods of correcting for multiple comparisons. 

1. What is pearson correlation coefficient?
2. What is covariance?
3. Correlation testing
4. Correlation matrix syntax
5. Multiple comparison methods 

##Setting Environment 
```{r}
#Library necessary pacakges 
if(!require("dplyr")) install.packages("dplyr"); library(dplyr)
if(!require("ggplot2")) install.packages("ggplot2"); library(ggplot2)
if(!require("tidyverse")) install.packages("tidyverse");library(tidyverse)
if(!require("patchwork")) install.packages("patchwork");library(patchwork)

## Setting up the environment: anxiety & Corona

#Setting the anxiety data for plotting. Run this section if your environment is cleaned. 
anxiety <- read.csv("/Users/austinluor/Desktop/R_Workshop/Data/Fake_Study_Data.csv")
#Classifying the variables
anxiety$Subject_ID <- as.factor(anxiety$Subject_ID)
anxiety$Age <- as.numeric(anxiety$Age)
anxiety$Treatment_Group <- as.character(anxiety$Treatment_Group)


#Creating a new catagorical variable 
anxiety$agegroup <- NA
anxiety$agegroup[anxiety$Age < 25] <- "YA"
anxiety$agegroup[anxiety$Age > 25] <- "MA"
anxiety$agegroup[anxiety$Age > 45] <- "OA"


#################
#Setting the coronavirus dataset for plotting. 
corona <- readxl:::read_excel("/Users/austinluor/Desktop/R_Workshop/Data/coronavirus_dataset_shortened.xlsx", col_types = c("text", "text", "numeric","numeric", "date", "numeric", "text"))

#Reclassify variables, is everything in the right category? If not, modify it 
corona$Province.State <- as.character(corona$Province.State)
corona$Country.Region <- as.character(corona$Country.Region)
corona$Lat <- as.numeric(corona$Lat)
corona$Long <- as.numeric(corona$Long)
corona$cases <- as.numeric(corona$cases)
corona$type <- as.character(corona$type)

#Using the filter function to create a smaller dataframe for France
corona_france <- filter(.data= corona, corona$Country.Region == "France")
corona_france <- filter(.data= corona_france, corona_france$type == "confirmed")
newscoverage <- sample(1:100, 89, replace =TRUE)

corona_france$newscoverage <- newscoverage
corona_france <- cbind(corona_france, newscoverage)
corona_france["newscoverage"] <- newscoverage


#Create another smaller dataframe for Japan, US, and South Korea
Japan <- filter(.data= corona, corona$Country.Region == "Japan")
US <- filter(.data= corona, corona$Country.Region == "US")
France <- filter(.data= corona, corona$Country.Region == "France")
South_Korea <- filter(.data= corona, corona$Country.Region == "Korea, South")

#Create a separate dataframe for China
China <- filter(.data= corona, corona$Country.Region == "China")

#QUESTION 3
#Find out how many total cities are there: using this function will tell us how many distinct items are in the column. In this case, there are 5 unique cities in this dataframe
n_distinct(China$Province.State)

#3. Find the mean of confirmed cases for each city in China
China_confirmed <- filter(.data= China, China$type == "confirmed")

mean(China_confirmed$cases[China_confirmed$Province.State == "Anhui"])
mean(China_confirmed$cases[China_confirmed$Province.State == "Beijing"])
mean(China_confirmed$cases[China_confirmed$Province.State == "Chongqing"])
mean(China_confirmed$cases[China_confirmed$Province.State == "Fujian"])
mean(China_confirmed$cases[China_confirmed$Province.State == "Gansu"])

```

##Pearson's Correlation Coefficient (r)

You have probably heard this statement used over and over before in scientific research: "This variable X is highly correlated with variable Y and thus...blah blah blah". No doubt that this is one of the most widely used statistical methods among researchers today to see the relationship between two variables before going deeper with regression analysis. 

Why is it that researchers LOVE looking at correlations? 

*1. Easy way to measure thes strength of the linear relationship between two continous variables*

*2. Easy to interpret: The measure varies from +1 (perfect positive relationship between variables) to -1 (perfect negative relationship between variables) and 0 denotes a "no relationship between two variables"*


I will be using this made up small dataframe from the task on previous lesson. Suppose that we want to know if investing in advertisement helps to incrase profit in these 8 airline companies. We create a dataframe with three columns: airline, profit (by %), and investment (by million).
```{r, echo=FALSE,eval=TRUE, message= FALSE}
#A dataframe with two continuous variables study time vs. exam score
airline_profit <- data.frame(airline=c("Delta","JetBlue","Southwest","United","American","Spirit","Frontier","Alaska"),
                      profit=c(2,4,3.5,12,5,1,0.5,4.5),
                      invest=c(10,20,15,40,25,5,2.5,20))

airline_profit


#To see a really ugly but easy correlation matrix, you just need to use cor(). But why wouldn't this work?
cor(airline_profit)

#Use cor() to generate a simple correlation matrix. The reason why the previous code wouldn't work is because you need continuous variables in order to run a correlation matrix. "Airlines" is considered a character type. As you can see these variables are highly correlated with one another, r=0.9712616
cor(airline_profit[,2:3])
```

Pearson r correlation coefficient takes in the formula: *covariance / standard deviation of two variables*


##Covariance
In order to understand the computation of correlation, we need to understand what covariance is. We've definitely heard people throw this term here and there in their analysis, but what does covariance actually mean? Covariance tells us whether there is a relation between the deviations of two different variables from their mean. You need to sum (X - Xmean) * (Y-Ymean). In other words: *How far each observation is from the mean*

The covariance can be *POSITIVE*: if both values deviate in the same direction from the mean
The covariance can be *NEGATIVE*: if values are deviate in opposite direction from the mean

Here, let's visualize what this means when covariance is positive or negative. Using the same data, I have calculated:

1. the deviation of every value in profit column subtract the mean of profit
2. the deviation of every value in invest column subtract the mean of invest
3. crossproduct, which is the multiplication of two deviations 

This tells us the distance of every value from their mean.
```{r, echo=FALSE,eval=TRUE, message= FALSE}
if(!require("dplyr")) install.packages("dplyr"); library(dplyr)

airline_profit <- data.frame(airline=c("Delta","JetBlue","Southwest","United","American","Spirit","Frontier","Alaska"),
                      profit=c(2,4,3.5,12,5,1,0.5,4.5),
                      invest=c(10,20,15,40,25,5,2.5,20),
                      profit_deviant= airline_profit$profit - mean(airline_profit$profit),
                      invest_deviant= airline_profit$invest - mean(airline_profit$invest))

#Creating a new column called cross product, You can also use the mutate() function here from the wrangling lesson.                    
airline_profit$crossproduct = airline_profit$profit_deviant * airline_profit$invest_deviant

#Double check the final dataframe
airline_profit

```

For example: consider the first airline in profit_deviant. This means that airline A has 2 million profit and is slightly below the average (-2.06 mil) of other airlines. Airline A is also, on average, investing 7.18 million dollars less compare to what other airlines are investing in. 

```{r, echo=FALSE,eval=TRUE, message= FALSE}
#ggplot of the deviation
library(ggplot2)


#visualization of the variance at each point
air <-ggplot(airline_profit, aes(x=airline)) + 
  geom_point(aes(y=airline_profit$profit), color = "dark green", size = 3) +
  geom_hline(yintercept = mean(airline_profit$profit), color="green", size=0.5) + 
  geom_point(aes(y=airline_profit$invest), color = 'red', size =3) +
  geom_hline(yintercept = mean(airline_profit$invest), color = 'red', size=0.5) + 
  labs(title='Airline Profit; mean = 4.0625 Mil', y='millions (green), millions (red)', x= 'airlines') + ylim(-10, 45)



#Since United has the highest profit, let's take a look at how far United 's profit deviation is from the mean of profit 3.5million
air + 
  annotate('point', x=8, y=12, col = 'green', size = 5, alpha = 0.5) +
  annotate('segment', x=8, xend=8, y=4 ,yend=11, col = 'green', arrow= arrow(type = 'closed', length = unit(0.02, 'npc')))
  

#Looking at how far United's investment deviation is from the mean of investment 17.1875 Million
air + 
  annotate('point', x=8, y=12, col = 'green', size = 5, alpha = 0.5) + annotate('segment', x=8, xend=8, y=3.6 ,yend=11, col = 'green', arrow= arrow(type = 'closed', length = unit(0.02, 'npc'))) +
  annotate('point', x=8, y=40, col = 'red', size = 5, alpha = 0.5) + annotate('segment', x=8, xend=8, y=17.1875 ,yend=39, col = 'red', arrow= arrow(type = 'closed', length = unit(0.02, 'npc')))


```


Notice how both of these deviation values are positive because they are going at a direction that is greater than their mean? If you multiply for the crossproduct, you will get a POSITIVE value. This is what I mean when the covariance will be positive when you have two positive deviation or two negative deviation. Make sense right? 

Adding labels here again to show you that I am not lying.
```{r, echo=FALSE,eval=TRUE, message= FALSE}
#Adding labels; having the numeric deviation value of profit display next to the geom_point
air_profitlabel <- ggplot(airline_profit, mapping = aes(x=airline, y=profit_deviant)) + 
  geom_point(aes(y=airline_profit$profit), color = 'dark green') + 
  geom_hline(yintercept = mean(airline_profit$profit), color ='green', size=0.5) +
  annotate('point', x=8, y=12, col = 'green', size = 5, alpha = 0.5) +
  annotate('segment', x=8, xend=8, y=4 ,yend=11, col = 'green', arrow= arrow(type = 'closed', length = unit(0.02, 'npc'))) +
  annotate('point', x=8, y=12, col = 'green', size = 5, alpha = 0.5) + 
    geom_text(aes(label = paste0("(", airline_profit$profit_deviant, ")")), nudge_y = 8)

#view
air_profitlabel

#Adding labels; having the numeric deviation value of investment display next to the geom_point
air_investlabel <- ggplot(airline_profit, mapping = aes(x=airline, y=invest_deviant)) + 
  geom_point(aes(y=airline_profit$invest), color = 'red') + 
  geom_hline(yintercept = mean(airline_profit$invest), color = 'red', size=0.5) + 
  
  annotate('point', x=8, y=40, col = 'red', size = 5, alpha = 0.5) + annotate('segment', x=8, xend=8, y=17.1875 ,yend=39, col = 'red', arrow= arrow(type = 'closed', length = unit(0.02, 'npc'))) +
  geom_text(aes(label = paste0("(", airline_profit$invest_deviant, ")")), nudge_y = 8)

#View
air_investlabel


(air_profitlabel|air_investlabel)

```

Perfect, now that we got that covered, we can compute the covariance of these two variables. 

Compute the covariance: 
*Take the sum of cross product and divide it by the total number of observations - 1.*
```{r, echo=FALSE,eval=TRUE, message= FALSE}
covXY <- as.numeric(sum(airline_profit$crossproduct) / (nrow(airline_profit) - 1))

covXY
```


Okay great, now that we have the covariance as *42.16*, what do we do now?? This number doesn't really give any more insights to the dataset because covariance varies with the overall level of variance in the data.

so we are going to use this covariance and compute the pearson correlation between the two variables!

##Correlation
Correlation takes in the formula: Covariance/ std(x) * std(y). In our scenario: 42.16/std(profit) * std(invest)


*POP QUIZ: DO YOU KNOW WHY WE NEED TO DIVIDE IT BY THE STANDARD DEVIATION OF TWO VARIALBES?*

The reason why we have to divide it by the standard deviation of both variables is to "normalize" the differences. To normalize means that you are justifying the differences that make sense for both scales. 

Consider another scenario where profit is noted as % and investment is noted as millions. Such that the profit deviation for airline 4 is 8% and the investment deviation for airline 4 is 22.81 million. The fact that both numbers are not in the right units make it difficult to do any sort of comparison. Therefore, we multiple that deviation value by its standard deviation to "normalize" what we have so we can compare both numbers on the same level. 

```{r, echo=FALSE,eval=TRUE, message= FALSE}
corXY <- sum(airline_profit$crossproduct) / ((nrow(airline_profit) - 1) * sd(airline_profit$profit) * sd(airline_profit$invest))

corXY

#or

covXY/(sd(airline_profit$profit) * sd(airline_profit$invest))

#Print the correlation coefficient
print(corXY)
```

Recall that correlation coefficient takes in a range of values from -1 to 1 regardles of the data. A correlation of 1 indicates a perfect linear relationship. A correlation with -1 indicates a perfect negative relationship. Here we see that 
the profit and investment are highly correlated since corXY is *0.97126*. This means that the more that the airline invest in advertisement, the more profit the airline will receive. 

###Visualization of correlation matrix
For this section of the lesson, I will be using both rcorr() and corr.test() to compute pearson r as well as their p values. The syntax for correlation matrix is as follows:

1. Use either rcorr or corr.test to find out what the r, n, p are for each set of continuous variables.
2. Use corrplot() to visualize it.
3. Customization, including colors, p values, or crossing off pearson r if it is not significant. 

```{r, echo=FALSE,eval=TRUE, message= FALSE}
if(!require("Hmisc")) install.packages("Hmisc"); library(Hmisc)
if(!require("corrplot")) install.packages("corrplot"); library(corrplot)

#using the airline table as an correlation matrix. Not effective in terms of visualizing because we have established the fact that the correlation between the variables of interest is 0.9716 
#First use the rcorr to compute the correlation information
pearsonMatrix <- rcorr(as.matrix(airline_profit[,2:3]))

#Second, use the $ index to call out the pearson correlation coefficient, and display it with different methods. 
corrplot(pearsonMatrix$r, method = 'circle')
corrplot(pearsonMatrix$r, method = 'color')
corrplot(pearsonMatrix$r, method = 'ellipse')

#Using our previous worksheet example. Does age correlate with their shipley score?
testcorr <- data.frame(
           age=c(23,18,27,36,85,74,68,81),
           Shipley_score=c(16,17,13,15,16,16,18,19))

pearsonMatrix2 <- rcorr(as.matrix(testcorr))
corrplot(pearsonMatrix2$r, method = 'shade')
corrplot(pearsonMatrix2$r, method = 'number')
corrplot(pearsonMatrix2$r, method = 'pie')


```



### Customization of correlation matrix


```{r}

#Just like what we have did above, use the corr.test function to generate r, p, n 
anxietycorr<- corr.test(anxiety[,c(3:8,10:11)])


#Visualize what r p n means
anxietycorr$r #Pearson correlation croefficient values
anxietycorr$n #The number of observations
anxietycorr$p #The actual p values (corrected values will be shown on the upper half)


corrplot(anxietycorr$r, method = "color",
         p.mat = anxietycorr$p, sig.level = 0.05, insig = "blank",
         addCoef.col = "black", number.cex = 0.7, # Add coefficient of correlation
         tl.col="black", tl.srt=90, tl.cex = 1, #Text label color and rotation
         addgrid.col = "black",
         diag = FALSE, # hide correlation coefficient on the principal diagonal
         col=c("#F8766D", "#00BFC4"))

#only show the upper half. 
corrplot(anxietycorr$r, type = "upper", method = "color",
         p.mat = anxietycorr$p, sig.level = 0.05, insig = "blank",
         addCoef.col = "black", number.cex = 0.7, # Add coefficient of correlation
         tl.col="black", tl.srt=90, tl.cex = 1, #Text label color and rotation
         addgrid.col = "black",
         diag = FALSE, # hide correlation coefficient on the principal diagonal
         col=c("#F8766D", "#00BFC4"))

#Other ways you can do this. 
corrplot(anxietycorr$r, method = "color")


#Use the corr.test function to generate r, p, n with corrected p values. you can specify the methods.
anxietycorr<- corr.test(anxiety[,c(3:8,10:11)], adjust = "BH", alpha=.05)
```


##Task1: Shortening a dataframe to create a correlation matrix
```{r}
#Shorten the anxiety dataframe to age, SES, SelfReport, RelativeReport, Depression
anxietyshorten <- anxiety[,c(3:6,10)]

#Find the correlation identity using corr.test()
anxietyshorten <- corr.test(anxietyshorten)

#Use the corrplot function to draw out a simple correlation matrix using the color method
corrplot(anxietyshorten$r, method = "color")

#Use the corrplot function to draw out more informative correlation matrix.
corrplot(anxietyshorten$r, type = "upper", method = "color",
         p.mat = anxietyshorten$p, sig.level = 0.05, insig = "blank",
         addCoef.col = "black", number.cex = 0.7, # Add coefficient of correlation
         tl.col="black", tl.srt=90, tl.cex = 1, #Text label color and rotation
         addgrid.col = "black",
         diag = FALSE, # hide correlation coefficient on the principal diagonal
         col=c("#F8766D", "#00BFC4"))
```

##Task2: Create a correlation matrix using this dataframe All sample
```{r}
#reading in the dataframe
sampleA <- data.frame(subject=c("1","2","3","4","5","6","7","8","9","10"),
                     group=c("Y","Y","Y","Y","Y","Y","Y","Y","Y","Y"),
                     memory=c(315,311,308,332,312,320,325,330,327,320),
                     shipley=c(15,16,13,17,18,14,16,15,17,19),
                     MoCA=c(25,27,26,30,28,25,27,22,28,30),
                     perception= c(90,78,89,76,90,99,100,67,59, 85))
            
sampleB <-data.frame(subject=c("11","12","13","14","15","16","17","18","19","20"),
                     group=c("N","N","N","N","N","N","N","N","N","N"),
                     memory=c(305,312,330,301,305,308,312,321,311,320),
                     shipley=c(13,14,17,17,14,15,18,12,13,20),
                     MoCA=c(23,28,24,30,26,26,21,30,27,30),
                     perception= c(70,98,59,76,89,92,83,89,68,99))
#Combinding all data into one big dataframe
Allsample <- rbind(sampleA, sampleB)


#Using corr.test to compute correlation matrix of all continous variables
Allsample <- corr.test(Allsample[,c(3:6)])

#Using corrplot to create the plot for correlation matrix 
corrplot(Allsample$r, method="color",
         p.mat = Allsample$p, sig.level = 0.05, insig = "blank",
         addCoef.col = "black", number.cex = 0.7, # Add coefficient of correlation
         tl.col="black", tl.srt=90, tl.cex = 1, #Text label color and rotation
         addgrid.col = "black",
         diag = FALSE, # hide correlation coefficient on the principal diagonal
         col=c("#F8766D", "#00BFC4"))

```

